{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:51:23.725563Z",
     "start_time": "2021-11-04T15:51:23.510908Z"
    }
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez, Medline\n",
    "import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# we can use the search terms provided to query pubmed using entrez esearch. \n",
    "# This will provide us with a list of pmids to retrieve in medline format\n",
    "# this function takes the search terms in the query string and returns a dictionary \n",
    "# the dict keys are: the date of serach, the query string used, the total count returned and the list of pmids \n",
    "def search_terms_to_pmid_list(query_string, email, api_key):\n",
    "    # set the entrez variables which are set up in advance for each group/project\n",
    "    Entrez.email = email\n",
    "    Entrez.tool = \"genepopi_search_developer\"\n",
    "    Entrez.api_key = api_key    \n",
    "    # get todays date \n",
    "    date = datetime.datetime.today()\n",
    "    date = f'{date.year}_{date.month}_{date.day}_{date.hour}_{date.minute}'\n",
    "    # send the query string to entrez esearch with the retmax at 90,000\n",
    "    # note if the number of returned records is > retmax we will need to iterate over the search results using a moving start and end point.\n",
    "    search_results = Entrez.read(Entrez.esearch(db=\"pubmed\", term = query_string, retmax=90000))\n",
    "    # We can then save the total count returned and pmid list to new variables\n",
    "    t_count = int(search_results['Count'])\n",
    "    pmids = list(search_results['IdList'])\n",
    "    \n",
    "    # construct the output dict\n",
    "    results_d = {'date':date, 'search_term':query_string, 'total_count':t_count, 'pmids':pmids}\n",
    "    \n",
    "    # check if we need to batch the pmid list due to limit on retreival set to 90000\n",
    "    if t_count > 90000:\n",
    "        print(\"Your search query has returned more than 90,000 results\\nWe will need to batch the pmid retrieval\")\n",
    "        \n",
    "        start = len(pmids)\n",
    "        while start != t_count:\n",
    "            start+=1\n",
    "            \n",
    "            search_results = Entrez.read(Entrez.esearch(db=\"pubmed\", term = query_string, retmax=90000, retstart = start))\n",
    "            # We can then save the total count returned and pmid list to new variables\n",
    "            pmids = list(search_results['IdList'])\n",
    "        \n",
    "            # update the output dict to add on the new pmids\n",
    "            previous = results_d['pmids']\n",
    "            previous.extend(pmids)\n",
    "                        \n",
    "            results_d.update({'pmids':previous})\n",
    "            \n",
    "            start += len(pmids)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # save the output dictionary for our records of what terms used and number of records returned for a given date.\n",
    "    pickle.dump(results_d, open(f'./{date}.p', 'wb'))\n",
    "\n",
    "    return results_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:51:25.476309Z",
     "start_time": "2021-11-04T15:51:25.474250Z"
    }
   },
   "outputs": [],
   "source": [
    "# set your email\n",
    "email = 'email_address'\n",
    "# add your NCBI api_key - **** register your email and generate an api key here https://www.ncbi.nlm.nih.gov/account/settings/\n",
    "api_key = 'api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:51:27.344482Z",
     "start_time": "2021-11-04T15:51:27.252569Z"
    }
   },
   "outputs": [],
   "source": [
    "ddg2p_df = pd.read_csv('path_to_ddg2p.csv)\n",
    "ddg2p_genes = list(set(ddg2p_df['gene symbol']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gene symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:51:44.927260Z",
     "start_time": "2021-11-04T15:51:44.925106Z"
    }
   },
   "outputs": [],
   "source": [
    "genes = ddg2p_genes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can store the output from the search as a dictionary then dataframe\n",
    "gene_d = {}\n",
    "for gene in genes:\n",
    "    results_d = search_terms_to_pmid_list(gene, email, api_key)\n",
    "    gene_d.update({gene:{'count':results_d['total_count'], 'pmids':results_d['pmids']}})\n",
    "    \n",
    "    # now lets make each gene's pmids as a text string to file\n",
    "    pmids_str = (',').join(results_d['pmids'])\n",
    "    with open(f'{gene}_pmids.txt', 'w+') as file:\n",
    "        file.write(pmids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build the df to look at the counts and pmids quickly\n",
    "gene_df = pd.DataFrame.from_dict(gene_d, orient = 'index')\n",
    "pickle.dump(gene_df, open('gene_df.p', 'wb'))\n",
    "gene_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gene symbol[ti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T15:51:37.117652Z",
     "start_time": "2021-11-04T15:51:37.052216Z"
    }
   },
   "outputs": [],
   "source": [
    "genes_ti = [f'{i}[TI]' for i in genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can store the output from the search as a dictionary then dataframe\n",
    "gene_ti_d = {}\n",
    "for gene in genes_ti:\n",
    "    results_d = search_terms_to_pmid_list(gene, email, api_key)\n",
    "    gene_ti_d.update({gene:{'count':results_d['total_count'], 'pmids':results_d['pmids']}})\n",
    "    \n",
    "#     # now lets make each gene's pmids as a text string to file\n",
    "    pmids_str = (',').join(results_d['pmids'])\n",
    "    with open(f'{gene}_ti_pmids.txt', 'w+') as file:\n",
    "        file.write(pmids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build the df to look at the counts and pmids quickly\n",
    "\n",
    "gene_ti_df = pd.DataFrame.from_dict(gene_ti_d, orient = 'index')\n",
    "pickle.dump(gene_ti_df, open('gene_ti_df.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the cadmus pmids and save as a string.\n",
    "all_pmids = []\n",
    "for pmids in gene_ti_df['pmids']:\n",
    "    all_pmids.extend(pmids)\n",
    "print(f'there are {len(all_pmids)} pmids found from our {len(gene_ti_df)} gene search')\n",
    "\n",
    "cadmus_pmids = list(set(all_pmids))\n",
    "print(f'There are {len(cadmus_pmids)} unique pmids to get metadata for')\n",
    "\n",
    "with open('cadmus_ti_pmids.txt', 'w+') as file:\n",
    "    file.write(','.join(cadmus_pmids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gene symbol [tiab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_tiab = [f'{i}[TIAB]' for i in genes]  \n",
    "\n",
    "# we can store the output from the search as a dictionrary then dataframe\n",
    "gene_tiab_d = {}\n",
    "for gene in genes_tiab:\n",
    "    results_d = search_terms_to_pmid_list(gene, email, api_key)\n",
    "    gene_tiab_d.update({gene:{'count':results_d['total_count'], 'pmids':results_d['pmids']}})\n",
    "    \n",
    "    # now lets make each gene's pmids as a text string to file\n",
    "    pmids_str = (',').join(results_d['pmids'])\n",
    "    with open(f'{gene}_tiab_pmids.txt', 'w+') as file:\n",
    "        file.write(pmids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build the df to look at the counts and pmids quickly\n",
    "\n",
    "gene_tiab_df = pd.DataFrame.from_dict(gene_tiab_d, orient = 'index')\n",
    "pickle.dump(gene_tiab_df, open('gene_tiab_df.p', 'wb'))\n",
    "gene_tiab_df.sort_values(by='count',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the cadmus pmids and save as a string.\n",
    "all_pmids = []\n",
    "for pmids in gene_tiab_df['pmids']:\n",
    "    all_pmids.extend(pmids)\n",
    "print(f'there are {len(all_pmids)} pmids found from our {len(gene_tiab_df)} gene search')\n",
    "\n",
    "cadmus_pmids = list(set(all_pmids))\n",
    "print(f'There are {len(cadmus_pmids)} unique pmids to get metadata for')\n",
    "\n",
    "with open('cadmus_tiab_pmids.txt', 'w+') as file:\n",
    "    file.write(','.join(cadmus_pmids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gene[mesh] gene symbol[tiab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_mesh_tiab = [f'gene[MESH] {i}[TIAB]' for i in genes]  \n",
    "\n",
    "# we can store the output from the search as a dictionrary then dataframe\n",
    "gene_mesh_tiab_d = {}\n",
    "for gene in genes_mesh_tiab:\n",
    "    results_d = search_terms_to_pmid_list(gene, email, api_key)\n",
    "    gene_mesh_tiab_d.update({gene:{'count':results_d['total_count'], 'pmids':results_d['pmids']}})\n",
    "    \n",
    "    # now lets make each gene's pmids as a text string to file\n",
    "    pmids_str = (',').join(results_d['pmids'])\n",
    "    with open(f'{gene}_mesh_tiab_pmids.txt', 'w+') as file:\n",
    "        file.write(pmids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build the df to look at the counts and pmids quickly\n",
    "\n",
    "gene_mesh_tiab_df = pd.DataFrame.from_dict(gene_mesh_tiab_d, orient = 'index')\n",
    "pickle.dump(gene_mesh_tiab_df, open('gene_tiab_df.p', 'wb'))\n",
    "gene_mesh_tiab_df.sort_values(by='count',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the cadmus pmids and save as a string.\n",
    "all_pmids = []\n",
    "for pmids in gene_mesh_tiab_df['pmids']:\n",
    "    all_pmids.extend(pmids)\n",
    "print(f'there are {len(all_pmids)} pmids found from our {len(gene_mesh_tiab_df)} gene search')\n",
    "\n",
    "cadmus_pmids = list(set(all_pmids))\n",
    "print(f'There are {len(cadmus_pmids)} unique pmids to get metadata for')\n",
    "\n",
    "with open('cadmus_mesh_tiab_pmids.txt', 'w+') as file:\n",
    "    file.write(','.join(cadmus_pmids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4ebcaf47573c63dc6b29179b08c22882e80c076082f9c55472dd61f32ef8cb2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
